Реально считать метрики. Сейчас LMRepository читает только из lm_value. Либо запусти воркер, который будет писать в таблицу (см. save_lm_value/save_lm_values_batch), либо перепиши get_group_metrics и прочие методы, чтобы они на лету брали сырые данные из call_scores, call_history, lm_service и т.д.

Подключить расчёты. Посмотри app/services/lm_service.py — там лежит математика по скорингу (conversion, risk, forecast). Её нужно вызывать из воркера и сохранять результат в lm_value, чтобы AdminLMHandler мог их читать.

Короче: backend‑заготовки есть, но пока нет ни воркера, ни realtime‑агрегаторов. Поэтому ты видишь только бабл «Ошибка загрузки данных».

Обновить UI смысла нет — нужно либо поднять LM worker (который будет наполнять lm_value), либо дописать расчёты прямо в LMRepository/lm_service, чтобы они читали данные из call_scores в момент открытия.


Судя по репозиторию (app/db/repositories/lm_repository.py) и AdminLMHandler, набор LM‑метрик задуман таким:

Группировка operational – скорость реакции (response_speed_score), эффективность разговора (talk_time_efficiency), индекс влияния на очередь (queue_impact_index). Формула: чисто среднее/минимум/максимум по value_numeric из lm_value.

conversion – conversion_score, lost_opportunity_score, cross_sell_potential и т.п. Карточка “Конверсии” показывает avg (значения 0–100). Аналитика пока лишь агрегирует эти показатели.

quality – предполагаются метрики “покрытие чек-листа” и “risks” по скрипту (например checklist_coverage, script_risk_score). В текущем коде этих названий нет, значит они не реализованы или не подключены.

risk – churn_risk_level, complaint_risk_flag, followup_needed_flag. 方法 get_risk_summary агрегирует количество high/medium/low по value_label и флаги жалоб/фоллоу-апов.

forecast – conversion_prob_forecast, second_call_prob, complaint_prob. В карточке рассчитываются проценты и выводятся статусы.

То есть “математика” (модели) предполагается в другом месте: эти значения должны быть записаны в таблицу lm_value (через save_lm_value). Пока этого воркера нет — поэтому ты видишь “Ошибка загрузки данных”.
Если нужно реальное поведение:

Реализовать LM worker или сервис, который заполняет lm_value по звонкам (см. lm_service.py для правил).
Или переписать LMRepository, чтобы он считал метрики на лету из call_history/call_scores.
Сейчас карточки лишь берут средние значения из lm_value. Пока таблица пустая — и “какая математика” нигде не исполняется.
Сейчас LM‑кнопки используют LMRepository, который читает таблицу lm_value. Колонки ml_* в call_scores уже удалены, а воркер, который когда‑то наполнял lm_value, не запущен, поэтому всё падает. Чтобы реализовать “online” расчёт без записи в таблицу, нужна отдельная разработка:

Определить «сырые» источники: call_scores, call_history, analytics — оттуда брать данные (например, длительность, исход, оценки).

В LMRepository или отдельном сервисе реализовать методы, которые по запросу прогоняют математику (формулы из lm_service.py) и возвращают агрегаты (средние, вероятность жалобы и т.д.), не опираясь на lm_value.

Хендлер AdminLMHandler будет вызывать эти новые методы (а не get_group_metrics), и кнопка “Обновить” реально пересчитает показатели.

Это большая задача: нужно продумать формулы, откуда брать данные, какие ограничения по производительности. В текущем коде ничего этого нет, поэтому кнопка “LM метрики” — пустой интерфейс.