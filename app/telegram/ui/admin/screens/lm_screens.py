
"""–≠–∫—Ä–∞–Ω—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LM-–º–µ—Ç—Ä–∏–∫–∞–º–∏."""

import json
import re
import html
from typing import List, Dict, Any, Optional, Tuple
from datetime import date, datetime, timezone
from zoneinfo import ZoneInfo
from telegram import InlineKeyboardButton

from app.telegram.ui.admin.screens import Screen
from app.telegram.utils.callback_lm import LMCB
from app.telegram.utils.callback_data import AdminCB
from app.services.lm_rules import METRIC_CONFIG, get_badge, decline_word
from app.logging_config import get_watchdog_logger

MIN_SAMPLE_SIZE = 30
LM_TRANSCRIPT_SNIPPET_LIMIT = 500

WORD_FORMS = {
    "call": ("–∑–≤–æ–Ω–æ–∫", "–∑–≤–æ–Ω–∫–∞", "–∑–≤–æ–Ω–∫–æ–≤"),
    "task": ("–∑–∞–¥–∞—á–∞", "–∑–∞–¥–∞—á–∏", "–∑–∞–¥–∞—á"),
    "client": ("–∫–ª–∏–µ–Ω—Ç", "–∫–ª–∏–µ–Ω—Ç–∞", "–∫–ª–∏–µ–Ω—Ç–æ–≤"),
}

STATUS_ICONS = {
    "green": "üü¢",
    "yellow": "üü°",
    "red": "üî¥",
    "gray": "‚ö™",
}

MOSCOW_TZ = ZoneInfo("Europe/Moscow")

logger = get_watchdog_logger(__name__)

METHODOLOGY_SECTIONS = [
    {
        "title": "Response speed score (1‚Äì5)",
        "lines": [
            "–ß—Ç–æ: –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞ –¥–æ –æ—Ç–≤–µ—Ç–∞ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞.",
            "–ö–∞–∫: –∏—Å–ø–æ–ª—å–∑—É–µ–º call_history.await_sec –∏ —Å—Ç—É–ø–µ–Ω–∏ &lt;20 / 40 / 60 / 120 —Å–µ–∫—É–Ω–¥.",
            "–ü–æ—Ä–æ–≥: &lt;2 –±–∞–ª–ª–æ–≤ (–æ–∂–∏–¥–∞–Ω–∏–µ >60 c) = –∫—Ä–∞—Å–Ω—ã–π —Å—Ç–∞—Ç—É—Å, —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–∞–∑–±–æ—Ä –æ—á–µ—Ä–µ–¥–∏.",
        ],
    },
    {
        "title": "Talk time efficiency (0‚Äì100)",
        "lines": [
            "–ß—Ç–æ: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ª–∏–Ω–∏–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏ –∫–ª–∏–µ–Ω—Ç–∞.",
            "–ö–∞–∫: –±–µ—Ä—ë–º talk_duration, –Ω–æ—Ä–º–∏—Ä—É–µ–º (–¥–ª–∏–Ω–Ω—ã–µ —Ä–∞–∑–≥–æ–≤–æ—Ä—ã ‚â•60 c —Ä–µ–∂—É—Ç—Å—è –∫–∞–ø–æ–º).",
            "–ü–æ—Ä–æ–≥: &lt;40 –±–∞–ª–ª–æ–≤ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∫–æ–Ω—Ç–∞–∫—Ç—ã —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ —Ä–∏—Å–∫ –Ω–µ–¥–æ—Å–∫–∞–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≤—ã—Å–æ–∫.",
        ],
    },
    {
        "title": "Conversion score (0‚Äì100)",
        "lines": [
            "–ß—Ç–æ: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ –ø–æ—Å–ª–µ –∑–≤–æ–Ω–∫–∞.",
            "–ö–∞–∫: outcome='record' ‚Üí 100, 'lead_no_record' ‚Üí 50, –∏–Ω—Ñ–æ-–∑–≤–æ–Ω–∫–∏ ‚Üí 20, –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Üí 0.",
            "–ü–æ—Ä–æ–≥: &lt;60 –±–∞–ª–ª–æ–≤ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ —Å–≤–µ—Ç–æ—Ñ–æ—Ä ¬´–ö–æ–Ω–≤–µ—Ä—Å–∏—è¬ª –∏ —Ç—Ä–µ–±—É–µ—Ç –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä—É.",
        ],
    },
    {
        "title": "Complaint risk flag / complaint_prob",
        "lines": [
            "–ß—Ç–æ: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —ç—Å–∫–∞–ª–∞—Ü–∏–∏ –∂–∞–ª–æ–±—ã.",
            "–ö–∞–∫: —Å–ª–æ–≤–∞—Ä–∏ (lm_dictionary_terms) –≥—Ä—É–ø–ø A‚ÄìE + —Å—Ç–æ–ø-—Å–ª–æ–≤–∞, –≤–µ—Å–∞ —Ñ–∏–∫—Å–∏—Ä—É—é—Ç—Å—è –≤ –ë–î; –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã ‚Äî –Ω–∏–∑–∫–∏–π call_score, –¥–ª–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è ¬´–ñ–∞–ª–æ–±–∞¬ª.",
            "–ü–æ—Ä–æ–≥: complaint_score ‚â• 60 –∏–ª–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è (call_score ‚â§3 + talk ‚â•30 c) ‚Üí —Å–ø–∏—Å–æ–∫ ¬´‚ö†Ô∏è –ñ–∞–ª–æ–±—ã¬ª. –•–∏—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ lm_dictionary_hits.",
        ],
    },
    {
        "title": "–§–ª–∞–≥ ¬´–ù—É–∂–Ω–æ –ø–µ—Ä–µ–∑–≤–æ–Ω–∏—Ç—å¬ª",
        "lines": [
            "–ß—Ç–æ: –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–π –ø—Ä–æ—Ü–µ—Å—Å (–∫–ª–∏–µ–Ω—Ç –∂–¥—ë—Ç –¥–µ–π—Å—Ç–≤–∏—è –ø–æ—Å–ª–µ –∑–≤–æ–Ω–∫–∞).",
            "–ö–∞–∫: outcome ‚àà –ª–∏–¥–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤, call_category='–õ–∏–¥ (–±–µ–∑ –∑–∞–ø–∏—Å–∏)', –∫–æ–¥—ã –æ—Ç–∫–∞–∑–æ–≤ PATIENT_WILL_CLARIFY/CALL_BACK_LATER/THINKING/NO_TIME –∏–ª–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å–±–æ–π/non_target –ø—Ä–∏ —Ä–µ–∞–ª—å–Ω–æ–º –∫–ª–∏–µ–Ω—Ç–µ.",
            "–ü–æ—Ä–æ–≥: flag=true => –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–∑–≤–æ–Ω –≤ —Ç–µ—á–µ–Ω–∏–µ 24 —á–∞—Å–æ–≤ –∏ —Ñ–∏–∫—Å–∞—Ü–∏—è –∏—Å—Ö–æ–¥–∞.",
        ],
    },
    {
        "title": "Lost opportunity score / count",
        "lines": [
            "–ß—Ç–æ: –Ω–∞—Å–∫–æ–ª—å–∫–æ –±–æ–ª–µ–∑–Ω–µ–Ω–Ω–æ —É–ø—É—Å—Ç–∏–ª–∏ —Ü–µ–ª–µ–≤–æ–π –∑–≤–æ–Ω–æ–∫, –∏ —Å–∫–æ–ª—å–∫–æ –∏—Ö –≤ –ø–µ—Ä–∏–æ–¥–µ.",
            "–ö–∞–∫: is_target=1 –∏ outcome!='record' (–∏—Å–∫–ª—é—á–∞—è —Å–ø–∞–º) –¥–∞—é—Ç –±–∞–∑—É 60 –±–∞–ª–ª–æ–≤; +10 –∑–∞ talk_duration ‚â•30 c, +20 –ø—Ä–∏ call_score ‚â§4, +10 –µ—Å–ª–∏ refusal_reason –ø—É—Å—Ç–æ–π. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏–∫—Å–∏—Ä—É–µ–º –≤ summary –∫–∞–∫ lost_opportunity_count.",
            "–ü–æ—Ä–æ–≥: score ‚â• 60 –∑–∞–Ω–æ—Å–∏—Ç –∑–≤–æ–Ω–æ–∫ –≤ —Å–ø–∏—Å–æ–∫ ¬´üí∏ –ü–æ—Ç–µ—Ä–∏¬ª, KPI ‚Äî –¥–æ–ª—è —Ç–∞–∫–∏—Ö –∑–≤–æ–Ω–∫–æ–≤ –æ—Ç —Ü–µ–ª–µ–≤—ã—Ö.",
        ],
    },
]

def render_lm_summary_screen(
    history_id: int,
    metrics: Dict[str, Any],
    call_info: Optional[Dict[str, Any]] = None,
    action_context: Optional[str] = None,
    period_days: Optional[int] = None
) -> Screen:
    """
    –≠–∫—Ä–∞–Ω–∞ —Å–≤–æ–¥–∫–∏ LM (Level 3.3: –û–¥–∏–Ω –∑–≤–æ–Ω–æ–∫).
    action_context: –∏–∑ –∫–∞–∫–æ–≥–æ —Å–ø–∏—Å–∫–∞ –ø—Ä–∏—à–ª–∏ (followup, complaints, lost, churn)
    """
    from app.services.lm_rules import METRIC_CONFIG, EVIDENCE_RULES, get_badge
    
    # 1. –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ
    caller = call_info.get('caller_number') or "–ó–≤–æ–Ω–æ–∫" if call_info else "–ó–≤–æ–Ω–æ–∫"
    date_dt = None
    if call_info:
        date_dt = call_info.get('context_start_time_dt') or call_info.get('call_date') or call_info.get('context_start_time')
    date_str = date_dt.strftime('%d.%m %H:%M') if date_dt else "‚Äî"
    operator = _extract_operator_name(call_info.get('called_info')) or "‚Äî"
    source = call_info.get('utm_source_by_number') or "‚Äî"
    outcome = call_info.get('outcome') or "‚Äî"
    call_score = call_info.get('call_score', "‚Äî")
    talk_duration = call_info.get('talk_duration', 0)
    
    # 2. –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å–≤–µ—Ç–æ—Ñ–æ—Ä–æ–≤
    speed = metrics.get('response_speed_score', {})
    efficiency = metrics.get('talk_time_efficiency', {})
    conversion = metrics.get('conversion_score', {})
    churn_lbl = metrics.get('churn_risk_level', {}).get('value_label', 'LOW')
    complaint_val = metrics.get('complaint_risk_flag', {}).get('value_numeric', 0)
    followup_data = metrics.get('followup_needed_flag', {}) or {}
    followup_flag = followup_data.get('value_label') == 'true'
    followup_reason = ((followup_data.get('value_json') or {}) if followup_data else {}).get('reason')

    speed_icon = get_badge(speed.get('value_numeric', 0), METRIC_CONFIG.get('response_speed_score', {'red': 2, 'yellow': 3}))
    churn_icon = "üî¥" if churn_lbl in ("CRITICAL", "HIGH") else "üü¢"
    complaint_icon = "‚ö†Ô∏è" if complaint_val >= 60 else "‚úÖ"
    followup_icon = "üìû" if followup_flag else "‚úÖ"

    text = (
        f"üéØ <b>–ó–≤–æ–Ω–æ–∫ #{history_id}</b>\n"
        f"<b>–î–∞—Ç–∞/–≤—Ä–µ–º—è:</b> {date_str}\n"
        f"<b>–û–ø–µ—Ä–∞—Ç–æ—Ä:</b> {operator}\n"
        f"<b>–ò—Å—Ç–æ—á–Ω–∏–∫:</b> {source}\n"
        f"<b>–ò—Å—Ö–æ–¥:</b> {outcome}\n"
        f"<b>–°–∫–æ—Ä:</b> {call_score}\n"
        f"<b>–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:</b> {talk_duration}s\n\n"
    )
    
    metric_reasons: List[str] = []
    has_evidence = False
    
    # –†–µ–∑–æ–Ω—ã –∏–∑ value_json (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
    context_keys = ["complaint_risk_flag", "followup_needed_flag", "lost_opportunity_score"]
    for ck in context_keys:
        m_data = metrics.get(ck, {})
        m_json = m_data.get("value_json") or {}
        if not m_json:
            continue
        reasons = m_json.get("reasons") or m_json.get("dictionary_hits_summary") or []
        for reason in reasons:
            clean_reason = str(reason).strip()
            if clean_reason:
                metric_reasons.append(f"‚Ä¢ {clean_reason}")
                has_evidence = True
        hits = m_json.get("hits") or []
        for hit in hits[:3]:
            term = hit.get("term")
            if not term:
                continue
            impact = hit.get("impact") or hit.get("weight")
            snippet = hit.get("snippet")
            hit_line = f"‚Ä¢ –¢—Ä–∏–≥–≥–µ—Ä ¬´{term}¬ª"
            if impact:
                try:
                    hit_line += f" (+{float(impact):.0f})"
                except (TypeError, ValueError):
                    pass
            if snippet:
                hit_line += f": {snippet}"
            metric_reasons.append(hit_line)
            has_evidence = True
        for snippet in (m_json.get("snippets") or [])[:2]:
            text_snippet = str(snippet).strip()
            if text_snippet:
                metric_reasons.append(f"‚§∑ {text_snippet}")
                has_evidence = True
        if ck == "lost_opportunity_score" and m_json.get("loss_category"):
            metric_reasons.append(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è –æ—Ç–∫–∞–∑–∞: {m_json['loss_category']}")
            has_evidence = True
        if m_json.get("requires_reason"):
            metric_reasons.append("‚ö†Ô∏è –ü—Ä–∏—á–∏–Ω–∞ –æ—Ç–∫–∞–∑–∞ –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∞ ‚Äî —Ç—Ä–µ–±—É–π—Ç–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã—Ç–∏–µ–º –∫–µ–π—Å–∞.")
            has_evidence = True
        if m_json.get("result_excerpt"):
            metric_reasons.append(f"üìù –ê–Ω–∞–ª–∏–∑: {m_json['result_excerpt']}")
            has_evidence = True

    transcript_truncated = False

    # 3. –ë–ª–æ–∫ "–ü–æ—á–µ–º—É –≤ —Å–ø–∏—Å–∫–µ" –∏ "–ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å"
    if action_context and action_context != "none":
        text += f"üìÇ <b>–†–∞–∑–¥–µ–ª: {action_context.upper()}</b>\n"
        
        if not metric_reasons and action_context in EVIDENCE_RULES:
            item_for_rules = {**call_info} if call_info else {}
            item_for_rules.update({k: v.get('value_numeric') for k, v in metrics.items() if 'value_numeric' in v})
            item_for_rules.update({k: v.get('value_label') for k, v in metrics.items() if 'value_label' in v})
            
            rules = EVIDENCE_RULES[action_context]
            for r in rules:
                try:
                    if r['condition'](item_for_rules):
                        metric_reasons.append(f"‚Ä¢ {r['text'].format(**item_for_rules)}")
                except Exception: continue

        if metric_reasons:
            unique_reasons = []
            seen = set()
            for r in metric_reasons:
                clean_r = str(r).strip()
                if clean_r and clean_r not in seen:
                    unique_reasons.append(clean_r)
                    seen.add(clean_r)
            text += "<b>–ü–æ—á–µ–º—É –≤ —Å–ø–∏—Å–∫–µ:</b>\n" + "\n".join(unique_reasons[:8]) + "\n\n"
        
        analysis = call_info.get("result") or call_info.get("operator_result")
        if analysis:
            short_analysis = str(analysis)[:400] + ("..." if len(str(analysis)) > 400 else "")
            text += f"üîç <b>–ê–Ω–∞–ª–∏–∑ –∑–≤–æ–Ω–∫–∞:</b>\n<i>{short_analysis}</i>\n\n"
        refusal_reason_text = (call_info.get("refusal_reason") or call_info.get("refusal_comment") or "").strip()
        if refusal_reason_text:
            text += f"üö´ <b>–ü—Ä–∏—á–∏–Ω–∞ –æ—Ç–∫–∞–∑–∞:</b> {html.escape(refusal_reason_text)}\n\n"
        transcript_text = call_info.get("transcript") or call_info.get("raw_transcript")
        if transcript_text:
            snippet_raw = _strip_html(str(transcript_text)).strip()
            if snippet_raw:
                snippet = snippet_raw[:LM_TRANSCRIPT_SNIPPET_LIMIT]
                if len(snippet_raw) > LM_TRANSCRIPT_SNIPPET_LIMIT:
                    snippet = snippet.rstrip() + "‚Ä¶"
                    transcript_truncated = True
                safe_snippet = html.escape(snippet)
                text += f"üìù <b>–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ (—Ñ—Ä–∞–≥–º–µ–Ω—Ç):</b>\n<code>{safe_snippet}</code>\n\n"
                if transcript_truncated:
                    text += "<i>–¢–µ–∫—Å—Ç —Å–æ–∫—Ä–∞—â—ë–Ω. –ù–∞–∂–º–∏—Ç–µ ¬´–ü–æ–∫–∞–∑–∞—Ç—å –±–æ–ª—å—à–µ¬ª, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –ø–æ–ª–Ω—É—é —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É.</i>\n\n"

        mapping = {
            "followup": "followup_needed_flag",
            "complaints": "complaint_risk_flag",
            "lost": "lost_opportunity_score",
            "churn": "churn_risk_level"
        }
        conf = METRIC_CONFIG.get(mapping.get(action_context, ""))
        if conf:
            text += f"‚úÖ <b>–ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å:</b>\n{conf['action_text']}\n\n"
    elif has_evidence:
         text += "üìå <b>–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –∑–≤–æ–Ω–∫–∞:</b>\n" + "\n".join(metric_reasons[:5]) + "\n\n"

    text += (
        "<b>–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:</b>\n"
        f"{speed_icon} –û–∂–∏–¥–∞–Ω–∏–µ: {speed.get('value_numeric', 0)}/5\n"
        f"‚ö° –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {efficiency.get('value_numeric', 0):.1f}\n"
        f"üí∞ –ö–æ–Ω–≤–µ—Ä—Å–∏—è: {conversion.get('value_numeric', 0):.1f}\n"
        f"{churn_icon} –†–∏—Å–∫ –æ—Ç—Ç–æ–∫–∞: {churn_lbl}\n"
        f"{complaint_icon} –†–∏—Å–∫ –∂–∞–ª–æ–±—ã: {'–î–ê' if complaint_val >= 60 else '–ù–ï–¢'}\n"
        f"{followup_icon} –ù—É–∂–Ω–æ –ø–µ—Ä–µ–∑–≤–æ–Ω–∏—Ç—å: {'–ù–£–ñ–ï–ù' if followup_flag else '–ù–ï–¢'}\n"
    )
    if followup_flag and followup_reason:
        text += f"{followup_reason}\nSLA: –ø–µ—Ä–µ–∑–≤–æ–Ω–∏—Ç—å –≤ —Ç–µ—á–µ–Ω–∏–µ 24 —á–∞—Å–æ–≤.\n"
    
    # 4. –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞
    keyboard = []

    bundle_cb = AdminCB.create(
        AdminCB.CALL,
        "bundle",
        history_id,
        "lm",
        action_context or "none",
    )
    keyboard.append([
        InlineKeyboardButton(
            "üéß –ê—É–¥–∏–æ –∏ —Ç–µ–∫—Å—Ç",
            callback_data=bundle_cb,
        )
    ])
    if transcript_truncated:
        full_cb = AdminCB.create(
            AdminCB.CALL,
            "full_transcript",
            history_id,
            "lm",
            action_context or "none",
        )
        keyboard.append([
            InlineKeyboardButton(
                "üìÑ –ü–æ–∫–∞–∑–∞—Ç—å –±–æ–ª—å—à–µ",
                callback_data=full_cb,
            )
        ])

    if action_context and action_context != "none":
        back_callback = LMCB.create(LMCB.ACTION_LIST, action_context, 0)
    else:
        back_callback = AdminCB.create(AdminCB.LM_MENU, AdminCB.lm_SUM, period_days or "")
    keyboard.append([InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data=back_callback)])

    return Screen(text=text, keyboard=keyboard, parse_mode="HTML")

def render_lm_action_list_screen(
    action_type: str,
    items: List[Dict[str, Any]],
    page: int = 0,
    total: int = 0,
    period_days: Optional[int] = None
) -> Screen:
    """
    –≠–∫—Ä–∞–Ω —Å–ø–∏—Å–∫–∞ –¥–µ–π—Å—Ç–≤–∏–π (¬´–ù—É–∂–Ω–æ –ø–µ—Ä–µ–∑–≤–æ–Ω–∏—Ç—å¬ª, —Ä–∏—Å–∫–∏).
    """
    titles = {
        "followup": "üìû –ù—É–∂–Ω–æ –ø–µ—Ä–µ–∑–≤–æ–Ω–∏—Ç—å",
        "complaints": "‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã–µ –∂–∞–ª–æ–±—ã",
        "churn": "üìâ –†–∏—Å–∫ —É—Ö–æ–¥–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤",
        "lost": "üí∏ –ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è",
    }
    title = titles.get(action_type, "–°–ø–∏—Å–æ–∫ –¥–µ–π—Å—Ç–≤–∏–π")
    
    rules = {
        "followup": "–ö–ª–∏–µ–Ω—Ç –∏–ª–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä –∂–¥—ë—Ç –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏—è –∫ —Ä–∞–∑–≥–æ–≤–æ—Ä—É. SLA: 24 —á–∞—Å–∞.",
        "complaints": "–ï—Å—Ç—å —è–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∞ –≤ –¥–∏–∞–ª–æ–≥–µ.",
        "churn": "–ö–ª–∏–µ–Ω—Ç—ã —Å –≤—ã—Å–æ–∫–∏–º —Ä–∏—Å–∫–æ–º —É—Ö–æ–¥–∞ ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è —É–¥–µ—Ä–∂–∞–Ω–∏–µ.",
        "lost": "–¶–µ–ª–µ–≤—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è –±–µ–∑ –∑–∞–ø–∏—Å–∏ ‚Äî –Ω—É–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –≤ –≤–æ—Ä–æ–Ω–∫—É.",
    }

    text_header = f"<b>{title}</b>\n"
    rule_text = rules.get(action_type)
    if rule_text:
        text_header += f"{rule_text}\n"

    if not items:
        text_header += "\n<i>–°–ø–∏—Å–æ–∫ –ø—É—Å—Ç. –•–æ—Ä–æ—à–∞—è —Ä–∞–±–æ—Ç–∞!</i>"
        text = text_header
    else:
        text_header += f"–í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {total}\n\n"
        entry_chunks: List[str] = []
        for i, item in enumerate(items, 1):
            h_id = item.get('history_id')
            created = item.get('call_date') or item.get('created_at')
            date_str = created.strftime('%d.%m %H:%M') if created else "‚Äî"
            operator = _extract_operator_name(item.get("called_info")) or "‚Äî"
            source = item.get("utm_source_by_number") or "‚Äî"
            outcome = item.get("outcome") or "‚Äî"
            call_score = item.get("call_score", "‚Äî")
            
            reasons, next_step = _describe_action_item(action_type, item)
            
            reasons = _shorten_text(reasons, 320)
            next_step = _shorten_text(next_step, 220)
            entry_chunks.append(
                f"#{h_id} | {date_str} | {operator} | {source}\n"
                f"–ò—Å—Ö–æ–¥: {outcome} | –°–∫–æ—Ä: {call_score}\n"
                f"–ü—Ä–∏—á–∏–Ω–∞: {reasons}\n"
                f"–î–µ–π—Å—Ç–≤–∏–µ: {next_step}\n\n"
            )
        MAX_TEXT = 3500
        text = text_header
        pruned = False
        added = 0
        for chunk in entry_chunks:
            if len(text) + len(chunk) > MAX_TEXT:
                pruned = True
                break
            text += chunk
            added += 1
        if pruned:
            remaining = len(entry_chunks) - added
            text = text.rstrip() + f"\n‚Ä¶–∏ –µ—â—ë {remaining} –∑–∞–ø–∏—Å–µ–π, –æ—Ç–∫—Ä–æ–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É."

    keyboard = []
    # –≠–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞ –∫–∞–∫ –∫–Ω–æ–ø–∫–∏ –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞
    for item in items:
        h_id = item.get('history_id')
        keyboard.append([
            InlineKeyboardButton(
                f"üîé –î–µ—Ç–∞–ª–∏ #{h_id}",
                callback_data=LMCB.create(LMCB.ACTION_SUMMARY, h_id, action_type),
            )
        ])
    
    # –ù–∞–≤–∏–≥–∞—Ü–∏—è
    nav_row = []
    if page > 0:
        nav_row.append(InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data=LMCB.create(LMCB.ACTION_LIST, action_type, page - 1)))
    if total > (page + 1) * 10:
        nav_row.append(InlineKeyboardButton("–í–ø–µ—Ä–µ–¥ ‚û°Ô∏è", callback_data=LMCB.create(LMCB.ACTION_LIST, action_type, page + 1)))
    
    if nav_row:
        keyboard.append(nav_row)
        
    keyboard.append([
        InlineKeyboardButton("‚óÄÔ∏è –í —Å–≤–æ–¥–∫—É LM", callback_data=AdminCB.create(AdminCB.LM_MENU, AdminCB.lm_SUM, period_days or "")),
        InlineKeyboardButton("üè† –ê–¥–º–∏–Ω–∫–∞", callback_data=AdminCB.create(AdminCB.BACK))
    ])
    
    return Screen(text=text, keyboard=keyboard, parse_mode="HTML")


def render_lm_periods_screen(
    summary: Dict[str, Any],
    selected_days: int,
    available_periods: tuple[int, ...],
) -> Screen:
    """
    –≠–∫—Ä–∞–Ω –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π LM-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–∏–≥–Ω–∞–ª—å–Ω–æ–π —Å–≤–æ–¥–∫–∏.
    """
    header = "üß† <b>LM-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞</b>\n"
    if not summary:
        text = header + "\n<i>–ù–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ LM –º–µ—Ç—Ä–∏–∫–∞–º –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥.</i>"
        keyboard = [
            [InlineKeyboardButton("üè† –í –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å", callback_data=AdminCB.create(AdminCB.DASHBOARD))],
            [InlineKeyboardButton("‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data=AdminCB.create(AdminCB.BACK))],
        ]
        return Screen(text=text, keyboard=keyboard)

    period_label = _format_period_label(summary.get("start_date"), summary.get("end_date"))
    calls_total = summary.get("call_count", 0)
    base = summary.get("base", {})
    lost_total = base.get("lost_opportunity_count")
    updated_at = summary.get("updated_at")
    coverage = summary.get("coverage")

    metrics = summary.get("metrics", {})
    flags = summary.get("flags", {})
    churn = summary.get("churn", {})
    action_counts = summary.get("action_counts") or {}

    complaint_metric_count = metrics.get("complaint_risk_flag", {}).get("alert_count", 0)
    followup_metrics = flags.get("followup_needed_flag", {}) or {}
    followup_metric_count = followup_metrics.get("true_count", 0)
    followup_total = followup_metrics.get("total") or 0
    lost_metrics = metrics.get("lost_opportunity_score", {}) or {}
    lost_metric_count = lost_metrics.get("alert_count", 0)
    lost_fact = base.get("lost_opportunity_count")
    if lost_fact is None:
        lost_fact = lost_metrics.get("count")
    lost_fact = int(lost_fact or 0)
    churn_metric_high = churn.get("high", 0)
    churn_total = sum(int(v or 0) for v in churn.values()) if churn else 0

    def _resolve_action_count(key: str, fallback: int) -> int:
        value = action_counts.get(key)
        if value is None:
            return int(fallback or 0)
        try:
            return int(value)
        except (TypeError, ValueError):
            return int(fallback or 0)

    complaint_count = _resolve_action_count("complaints", complaint_metric_count)
    followup_count = _resolve_action_count("followup", followup_metric_count)
    lost_count = _resolve_action_count("lost", lost_metric_count)
    churn_high = _resolve_action_count("churn", churn_metric_high)

    coverage_line = _build_coverage_text(coverage)

    text_parts = []
    text_parts.append("üß† <b>LM-–ê–ù–ê–õ–ò–¢–ò–ö–ê</b>")
    text_parts.append("‚ÑπÔ∏è –î–∞—à–±–æ—Ä–¥ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å ¬´—á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç¬ª. LM ‚Äî ¬´–ø–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–æ–∏–∑–æ—à–ª–æ –∏ —á—Ç–æ –¥–µ–ª–∞—Ç—å¬ª.")
    text_parts.append(f"<b>–ü–µ—Ä–∏–æ–¥:</b> {period_label} (–ø–æ—Å–ª–µ–¥–Ω–∏–µ {selected_days} –¥–Ω.)")
    if lost_total is not None:
        text_parts.append(f"<b>–ü–æ—Ç–µ—Ä–∏:</b> {lost_total} —Ü–µ–ª–µ–≤—ã—Ö –±–µ–∑ –∑–∞–ø–∏—Å–∏")
    text_parts.append(f"<b>–û–±–Ω–æ–≤–ª–µ–Ω–æ:</b> {_format_datetime(updated_at)}")
    text_parts.append("‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ‚éØ")

    text_parts.append("\n<b>‚ö° –ì–õ–ê–í–ù–û–ï</b>")
    text_parts.append(_build_headline(summary, calls_total).strip())

    text_parts.append("\n<b>‚úÖ –ß–¢–û –°–î–ï–õ–ê–¢–¨ –°–ï–ì–û–î–ù–Ø</b>")
    text_parts.append(
        _build_actions_today_section(
            complaint_count,
            followup_count,
            followup_total,
            lost_count,
            lost_fact,
            churn_high,
            churn_total,
            calls_total,
        ).strip()
    )

    text_parts.append("\n<b>üìå –ö–ê–ß–ï–°–¢–í–û –î–ê–ù–ù–´–•</b>")
    text_parts.append(_build_data_quality_section(summary, coverage_line).strip())

    text_parts.append("\n<b>üö¶ –ò–ù–î–ò–ö–ê–¢–û–†–´</b>")
    text_parts.append(_build_indicators_block(summary, calls_total).strip())

    loss_section = _build_loss_breakdown_section(summary)
    if loss_section:
        text_parts.append("\n<b>üí∏ –ü–û–¢–ï–†–ò</b>")
        text_parts.append(loss_section.strip())
    text_parts.append(_build_week_actions_section(summary).strip())

    text_parts.append("\n<b>üìÇ –°–ü–ò–°–ö–ò –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò</b>")
    text_parts.append(
        _build_action_lists_description(
            complaint_count,
            followup_count,
            followup_total,
            lost_count,
            lost_fact,
            churn_high,
            churn_total,
        ).strip()
    )

    keyboard: List[List[InlineKeyboardButton]] = []
    action_buttons: List[InlineKeyboardButton] = []
    if complaint_count:
        action_buttons.append(
            InlineKeyboardButton(
                f"‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã–µ –∂–∞–ª–æ–±—ã ({complaint_count})",
                callback_data=LMCB.create(LMCB.ACTION_LIST, "complaints", 0),
            )
        )
    if followup_count:
        action_buttons.append(
            InlineKeyboardButton(
                f"üìû –ù—É–∂–Ω–æ –ø–µ—Ä–µ–∑–≤–æ–Ω–∏—Ç—å ({followup_count})",
                callback_data=LMCB.create(LMCB.ACTION_LIST, "followup", 0),
            )
        )
    if lost_count:
        action_buttons.append(
            InlineKeyboardButton(
                f"üí∏ –ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è ({lost_count})",
                callback_data=LMCB.create(LMCB.ACTION_LIST, "lost", 0),
            )
        )
    if churn_high:
        action_buttons.append(
            InlineKeyboardButton(
                f"üìâ –û—Ç—Ç–æ–∫ ({churn_high})",
                callback_data=LMCB.create(LMCB.ACTION_LIST, "churn", 0),
            )
        )
    while action_buttons:
        keyboard.append(action_buttons[:2])
        action_buttons = action_buttons[2:]

    period_row: List[InlineKeyboardButton] = []
    for days in available_periods:
        label = f"{days} –¥–Ω."
        prefix = "‚úÖ" if days == selected_days else "üìÖ"
        period_row.append(
            InlineKeyboardButton(
                f"{prefix} {label}",
                callback_data=AdminCB.create(AdminCB.LM_MENU, AdminCB.lm_SUM, days),
            )
        )
    if period_row:
        keyboard.append(period_row)

    keyboard.append(
        [
            InlineKeyboardButton(
                "üìò –ú–µ—Ç–æ–¥–∏–∫–∞ —Ä–∞—Å—á—ë—Ç–∞",
                callback_data=LMCB.create(LMCB.ACTION_METHOD, "period", selected_days),
            )
        ]
    )

    keyboard.append(
        [
            InlineKeyboardButton(
                "üîÑ –û–±–Ω–æ–≤–∏—Ç—å",
                callback_data=AdminCB.create(AdminCB.LM_MENU, AdminCB.lm_SUM, selected_days),
            ),
            InlineKeyboardButton(
                "‚¨ÖÔ∏è –í –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å",
                callback_data=AdminCB.create(AdminCB.DASHBOARD),
            ),
        ]
    )
    keyboard.append(
        [
            InlineKeyboardButton("‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data=AdminCB.create(AdminCB.BACK)),
        ]
    )

    text = "\n".join(text_parts)
    return Screen(text=text, keyboard=keyboard, parse_mode="HTML")


def _build_headline(summary: Dict[str, Any], calls_total: int) -> str:
    metrics = summary.get("metrics", {})
    flags = summary.get("flags", {})
    summary_line = []

    if calls_total < MIN_SAMPLE_SIZE:
        return "‚ö™ –í—ã–±–æ—Ä–∫–∞ –º–∞–ª–∞ ‚Äî –¥–æ–∂–¥–∏—Ç–µ—Å—å –±–æ–ª—å—à–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏—è.\n"

    quality_value = metrics.get("normalized_call_score", {}).get("avg")
    followup_share = _safe_ratio(flags.get("followup_needed_flag", {}).get("true_count"), calls_total)
    complaint_count = metrics.get("complaint_risk_flag", {}).get("alert_count", 0)

    if quality_value is not None and quality_value < 65:
        summary_line.append("–∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤ –Ω–∏–∂–µ –Ω–æ—Ä–º—ã")
    if followup_share is not None and followup_share >= 0.10:
        summary_line.append("–º–Ω–æ–≥–æ –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã—Ö –∑–∞–¥–∞—á ¬´–ù—É–∂–Ω–æ –ø–µ—Ä–µ–∑–≤–æ–Ω–∏—Ç—å¬ª")
    if complaint_count:
        summary_line.append("–µ—Å—Ç—å –∫–µ–π—Å—ã –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞ –∂–∞–ª–æ–±—ã")

    if not summary_line:
        return "üü¢ –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –≤ –Ω–æ—Ä–º–µ ‚Äî –¥–µ—Ä–∂–∏—Ç–µ —Ç–µ–∫—É—â–∏–π —Ä–∏—Ç–º –∫–æ–Ω—Ç—Ä–æ–ª—è.\n"

    return "‚ö†Ô∏è " + "; ".join(summary_line) + ".\n"


def _build_actions_today_section(
    complaint_count: int,
    followup_count: int,
    followup_total: int,
    lost_count: int,
    lost_total: int,
    churn_high: int,
    churn_total: int,
    calls_total: int,
) -> str:
    if calls_total < MIN_SAMPLE_SIZE:
        return "‚ö™ –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –∑–≤–æ–Ω–∫–æ–≤ ‚Äì –¥–æ–∂–¥–∏—Ç–µ—Å—å –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö, –ø—Ä–µ–∂–¥–µ —á–µ–º –ø—Ä–æ–≤–æ–¥–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏—è.\n"

    entries: List[str] = []
    if complaint_count:
        entries.append(
            f"1) ‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã–µ –∂–∞–ª–æ–±—ã: {_format_with_word(complaint_count, WORD_FORMS['call'])} ‚Äî –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤ —Ç–µ—á–µ–Ω–∏–µ 24 —á–∞—Å–æ–≤ –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç."
        )
    if followup_count:
        entries.append(
            f"{len(entries)+1}) üìû –ù—É–∂–Ω–æ –ø–µ—Ä–µ–∑–≤–æ–Ω–∏—Ç—å: —Ñ–∞–∫—Ç {followup_total}, –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ {followup_count} ‚Äî –ø–µ—Ä–µ–∑–≤–æ–Ω–∏—Ç—å ‚â§24 —á –∏ –∑–∞–∫—Ä—ã—Ç—å –≤–æ–ø—Ä–æ—Å."
        )
    if lost_count:
        entries.append(
            f"{len(entries)+1}) üí∏ –ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è: —Ñ–∞–∫—Ç {lost_total}, –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ {lost_count} ‚Äî –¥–æ–≤–Ω–µ—Å—Ç–∏ –ø—Ä–∏—á–∏–Ω—É –æ—Ç–∫–∞–∑–∞ –∏ –≤–µ—Ä–Ω—É—Ç—å –∫–ª–∏–µ–Ω—Ç–∞ –≤ –≤–æ—Ä–æ–Ω–∫—É."
        )
    if churn_high:
        entries.append(
            f"{len(entries)+1}) üìâ –†–∏—Å–∫ —É—Ö–æ–¥–∞: —Ñ–∞–∫—Ç {churn_total}, –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ {churn_high} ‚Äî –Ω–∞–∑–Ω–∞—á–∏—Ç—å –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∑–∞ —É–¥–µ—Ä–∂–∞–Ω–∏–µ –∏ –æ—Ç—á–∏—Ç–∞—Ç—å—Å—è –≤ —Ç–µ—á–µ–Ω–∏–µ 48 —á–∞—Å–æ–≤."
        )

    if not entries:
        return "–°–µ–≥–æ–¥–Ω—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –Ω–µ—Ç ‚Äî –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π—Ç–µ –¥–∞—à–±–æ—Ä–¥.\n"
    return "\n".join(entries) + "\n"


def _build_week_actions_section(summary: Dict[str, Any]) -> str:
    coverage = summary.get("coverage") or {}
    operator_entry = coverage.get("operator") or {}
    utm_entry = coverage.get("utm") or {}
    operator_cov = operator_entry.get("percent") or 0.0
    utm_cov = utm_entry.get("percent") or 0.0
    refusal_cov = (coverage.get("refusal") or {}).get("percent") or 0.0
    utm_breakdown = summary.get("utm_breakdown") or []
    period_days = summary.get("period_days")
    period_label = f"\n–ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {period_days} –¥–Ω.:\n" if period_days else "\n"
    notes: List[str] = []
    if operator_cov < 20:
        notes.append(
            f"–û–ø–µ—Ä–∞—Ç–æ—Ä—ã –∑–∞–ø–æ–ª–Ω–µ–Ω—ã: {operator_cov:.0f}% ‚Äî —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ."
        )
    if utm_cov < 20:
        notes.append(
            f"–ò—Å—Ç–æ—á–Ω–∏–∫ –æ–±—Ä–∞—â–µ–Ω–∏—è –∑–∞–ø–æ–ª–Ω–µ–Ω: {utm_cov:.0f}% ‚Äî —Ä–∞–∑–±–æ—Ä –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω."
        )
    if refusal_cov < 20:
        notes.append(
            f"–ü—Ä–∏—á–∏–Ω—ã –æ—Ç–∫–∞–∑–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã: {refusal_cov:.0f}% ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ—Ç–µ—Ä—å –Ω–µ—Ç–æ—á–Ω–∞."
        )

    if notes:
        return period_label + "\n".join(notes) + "\n"

    if not utm_breakdown:
        return period_label + "–ò—Å—Ç–æ—á–Ω–∏–∫ –æ–±—Ä–∞—â–µ–Ω–∏—è: –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç.\n"

    def _format_share(value: Any) -> str:
        try:
            share_val = float(value)
        except (TypeError, ValueError):
            return "0%"
        if share_val.is_integer():
            return f"{int(share_val)}%"
        return f"{share_val:.1f}%"

    lines = [period_label + "–ò—Å—Ç–æ—á–Ω–∏–∫ –æ–±—Ä–∞—â–µ–Ω–∏—è"]
    for item in utm_breakdown:
        label = item.get("label") or "–ù–µ —É–∫–∞–∑–∞–Ω"
        if label.lower() in {"–Ω–µ —É–∫–∞–∑–∞–Ω", "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"}:
            continue
        count = int(item.get("count") or 0)
        share = _format_share(item.get("share"))
        lines.append(f"{label}: {count} —à—Ç—É–∫ ({share})")

    return "\n".join(lines) + "\n"


def _build_indicators_block(summary: Dict[str, Any], calls_total: int) -> str:
    metrics = summary.get("metrics", {})
    flags = summary.get("flags", {})
    churn = summary.get("churn", {}) or {}
    base = summary.get("base", {}) or {}
    blocks: List[str] = []

    def _status_phrase(code: str) -> Optional[str]:
        return {
            "green": "–≤ –Ω–æ—Ä–º–µ",
            "yellow": "–Ω–∏–∂–µ –Ω–æ—Ä–º—ã",
            "red": "–∫—Ä–∏—Ç–∏—á–Ω–æ",
        }.get(code)

    def _add_block(
        title: str,
        description: str,
        *,
        status: Optional[str] = None,
        icon: Optional[str] = None,
        fallback: Optional[str] = None,
    ) -> None:
        symbol = icon or STATUS_ICONS.get(status or "", "‚ö™")
        status_text = _status_phrase(status) if status else None
        if fallback:
            status_text = fallback
        header = f"{symbol} {title}"
        if status_text:
            header += f" ‚Äî {status_text}"
        block_lines = [header, description]
        blocks.append("\n".join(block_lines))

    # –ö–∞—á–µ—Å—Ç–≤–æ –æ–±—â–µ–Ω–∏—è
    quality = metrics.get("normalized_call_score", {})
    q_value = quality.get("avg")
    if q_value is None:
        _add_block("–ö–∞—á–µ—Å—Ç–≤–æ –æ–±—â–µ–Ω–∏—è", "–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤", icon="‚ö™", fallback="–¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
    else:
        status = _status_from_value(q_value, 70, 65)
        _add_block("–ö–∞—á–µ—Å—Ç–≤–æ –æ–±—â–µ–Ω–∏—è", "–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤", status=status, icon=STATUS_ICONS.get(status))

    # –ó–∞–ø–∏—Å–∏ —Å –æ–±—Ä–∞—â–µ–Ω–∏–π
    conversion = metrics.get("conversion_score", {})
    c_value = conversion.get("avg")
    if c_value is None:
        _add_block("–ó–∞–ø–∏—Å–∏ —Å –æ–±—Ä–∞—â–µ–Ω–∏–π", "–°–∫–æ–ª—å–∫–æ —Ü–µ–ª–µ–≤—ã—Ö –∑–≤–æ–Ω–∫–æ–≤ –¥–æ—à–ª–∏ –¥–æ –∑–∞–ø–∏—Å–∏", icon="‚ö™", fallback="–¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
    else:
        status = _status_from_value(c_value, 70, 60)
        _add_block("–ó–∞–ø–∏—Å–∏ —Å –æ–±—Ä–∞—â–µ–Ω–∏–π", "–°–∫–æ–ª—å–∫–æ —Ü–µ–ª–µ–≤—ã—Ö –∑–≤–æ–Ω–∫–æ–≤ –¥–æ—à–ª–∏ –¥–æ –∑–∞–ø–∏—Å–∏", status=status, icon=STATUS_ICONS.get(status))

    # –†–∏—Å–∫ –∂–∞–ª–æ–±
    complaint_metrics = metrics.get("complaint_risk_flag", {}) or {}
    complaint_count = complaint_metrics.get("alert_count", 0)
    complaint_sample = complaint_metrics.get("count") or calls_total
    if not complaint_sample:
        _add_block("–†–∏—Å–∫ –∂–∞–ª–æ–±", "–ó–≤–æ–Ω–∫–∏ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∞", icon="‚ö™", fallback="–¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
    elif complaint_sample < MIN_SAMPLE_SIZE:
        _add_block("–†–∏—Å–∫ –∂–∞–ª–æ–±", "–ó–≤–æ–Ω–∫–∏ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∞", icon="‚ö™", fallback="–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö")
    else:
        status = "red" if complaint_count else "green"
        status_text = "–µ—Å—Ç—å —Å–∏–≥–Ω–∞–ª—ã" if complaint_count else "–≤ –Ω–æ—Ä–º–µ"
        _add_block("–†–∏—Å–∫ –∂–∞–ª–æ–±", "–ó–≤–æ–Ω–∫–∏ —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –Ω–µ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∞", status=status, icon="‚ö†Ô∏è", fallback=status_text)

    # –¢—Ä–µ–±—É—é—Ç –ø–µ—Ä–µ–∑–≤–æ–Ω–∞
    followup_meta = flags.get("followup_needed_flag", {}) or {}
    followup_total = int(followup_meta.get("total") or 0)
    followup_count = int(followup_meta.get("true_count") or 0)
    followup_denominator = followup_total if followup_total else calls_total
    followup_share = _safe_ratio(followup_count, followup_denominator)
    if followup_share is None:
        _add_block("–¢—Ä–µ–±—É—é—Ç –ø–µ—Ä–µ–∑–≤–æ–Ω–∞", "–ö–ª–∏–µ–Ω—Ç –∂–¥–∞–ª –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏", icon="üìû", fallback="–¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
    else:
        status = _status_from_share(followup_share, 0.20, 0.10)
        _add_block("–¢—Ä–µ–±—É—é—Ç –ø–µ—Ä–µ–∑–≤–æ–Ω–∞", "–ö–ª–∏–µ–Ω—Ç –∂–¥–∞–ª –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏", status=status, icon="üìû")

    # –ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è
    lost_total = base.get("lost_opportunity_count")
    if lost_total is None:
        lost_total = metrics.get("lost_opportunity_score", {}).get("count", 0)
    lost_total = int(lost_total or 0)
    lost_count = metrics.get("lost_opportunity_score", {}).get("alert_count", 0)
    lost_denominator = lost_total if lost_total else calls_total
    lost_share = _safe_ratio(lost_count, lost_denominator) if lost_denominator else None
    if lost_share is None:
        _add_block("–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è", "–¶–µ–ª–µ–≤—ã–µ –∑–≤–æ–Ω–∫–∏ –±–µ–∑ –∑–∞–ø–∏—Å–∏", icon="üí∏", fallback="–¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
    else:
        status = _status_from_share(lost_share, 0.08, 0.15)
        _add_block("–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è", "–¶–µ–ª–µ–≤—ã–µ –∑–≤–æ–Ω–∫–∏ –±–µ–∑ –∑–∞–ø–∏—Å–∏", status=status, icon="üí∏")

    # –†–∏—Å–∫ —É—Ö–æ–¥–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤
    churn_counts = {k: int(v or 0) for k, v in churn.items()}
    churn_total = sum(churn_counts.values())
    churn_high = churn_counts.get("high", 0) + churn_counts.get("critical", 0)
    if churn_total == 0:
        _add_block("–†–∏—Å–∫ —É—Ö–æ–¥–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤", "–ö–ª–∏–µ–Ω—Ç—ã —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –æ—Ç—Ç–æ–∫–∞", icon="üìâ", fallback="–¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ")
    else:
        if churn_high > 0:
            status = "red"
        elif churn_counts.get("medium", 0) > 0:
            status = "yellow"
        else:
            status = "green"
        _add_block("–†–∏—Å–∫ —É—Ö–æ–¥–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤", "–ö–ª–∏–µ–Ω—Ç—ã —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –æ—Ç—Ç–æ–∫–∞", status=status, icon="üìâ")

    return "\n\n".join(blocks) + "\n"


def _build_action_lists_description(
    complaint_count: int,
    followup_count: int,
    followup_total: int,
    lost_count: int,
    lost_total: int,
    churn_high: int,
    churn_total: int,
) -> str:
    lines = [
        f"1. ‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã–µ –∂–∞–ª–æ–±—ã ({complaint_count})",
        f"2. üìû –ù—É–∂–Ω–æ –ø–µ—Ä–µ–∑–≤–æ–Ω–∏—Ç—å: —Ñ–∞–∫—Ç {followup_total}, –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ {followup_count}.",
        f"3. üí∏ –ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –æ–±—Ä–∞—â–µ–Ω–∏—è: —Ñ–∞–∫—Ç {lost_total}, –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ {lost_count}.",
        f"4. üìâ –†–∏—Å–∫ —É—Ö–æ–¥–∞: —Ñ–∞–∫—Ç {churn_total}, –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ {churn_high}.",
        "‚¨ÖÔ∏è –ù–∞–∑–∞–¥ | üîÑ –û–±–Ω–æ–≤–∏—Ç—å",
    ]
    return "\n".join(lines) + "\n"


def _build_coverage_text(coverage: Optional[Dict[str, Any]]) -> str:
    if not coverage:
        return "–Ω/–¥"
    parts = []
    labels = {
        "transcript": "—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç",
        "outcome": "–∏—Å—Ö–æ–¥",
        "refusal": "–ø—Ä–∏—á–∏–Ω–∞ –æ—Ç–∫–∞–∑–∞",
        "operator": "–æ–ø–µ—Ä–∞—Ç–æ—Ä",
    }
    for key, label in labels.items():
        entry = coverage.get(key) if coverage else None
        if entry and entry.get("percent") is not None:
            parts.append(f"{label}={entry['percent']:.1f}%")
        else:
            parts.append(f"{label}=–Ω/–¥")
    return ", ".join(parts)


def _build_data_quality_section(summary: Dict[str, Any], compact_line: str) -> str:
    coverage = summary.get("coverage") or {}
    if not coverage:
        return "<b>‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏ ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞.</b>\n"

    warning_lines: List[str] = []
    info_lines: List[str] = [compact_line]
    refusal = (coverage.get("refusal") or {}).get("percent") or 0.0
    operator = (coverage.get("operator") or {}).get("percent") or 0.0

    if refusal < 60:
        warning_lines.append(f"–ü—Ä–∏—á–∏–Ω–∞ –æ—Ç–∫–∞–∑–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∞ –Ω–∞ {refusal:.0f}% ‚Äî –∞–Ω–∞–ª–∏–∑ –ø–æ—Ç–µ—Ä—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω.")
    if operator < 80:
        warning_lines.append(f"–î–∞–Ω–Ω—ã–µ –ø–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞–º –∑–∞–ø–æ–ª–Ω–µ–Ω—ã –Ω–∞ {operator:.0f}% ‚Äî —Å–ª–æ–∂–Ω–µ–µ –≤–µ—Å—Ç–∏ —Ä–∞–∑–±–æ—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞.")

    bookings = summary.get("bookings") or []
    if bookings:
        top_strings = []
        for row in bookings[:3]:
            cat = row.get("call_category") or "–ë–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"
            cnt = row.get("cnt") or 0
            top_strings.append(f"{cat}: {cnt}")
        if top_strings:
            info_lines.append("–ó–∞–ø–∏—Å–∏ –ø–æ –∫–∞–Ω–∞–ª–∞–º –∑–∞ –ø–µ—Ä–∏–æ–¥: " + ", ".join(top_strings))

    if warning_lines:
        return (
            "<b>‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –¥–∞–Ω–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã</b>\n"
            + "\n".join(warning_lines)
            + ("\n" + "\n".join(info_lines) if info_lines else "")
            + "\n"
        )

    if len(info_lines) == 1:
        info_lines.append("–ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ ‚Äî –º–æ–∂–Ω–æ —Å–º–æ—Ç—Ä–µ—Ç—å –¥—Ä–∞–π–≤–µ—Ä—ã.")
    return "\n".join(info_lines) + "\n"


def _build_loss_breakdown_section(summary: Dict[str, Any]) -> str:
    breakdown = summary.get("loss_breakdown") or []
    if not breakdown:
        return ""
    lines: List[str] = []
    for item in breakdown[:3]:
        label = item.get("label") or "–ù–µ —É–∫–∞–∑–∞–Ω–æ"
        count = int(item.get("count") or 0)
        share_val = item.get("share")
        share_text = ""
        try:
            share_float = float(share_val)
            if share_float > 0:
                share_text = f" ({share_float:.0f}%)"
        except (TypeError, ValueError):
            share_text = ""
        lines.append(f"{label}: {count}{share_text}")
    if not lines:
        return ""
    return "\n".join(lines) + "\n"


def render_lm_methodology_screen(back_callback: Optional[str] = None) -> Screen:
    """–≠–∫—Ä–∞–Ω —Å –º–µ—Ç–æ–¥–∏–∫–æ–π —Ä–∞—Å—á—ë—Ç–∞ LM-–º–µ—Ç—Ä–∏–∫."""
    lines: List[str] = ["üìò <b>–ú–µ—Ç–æ–¥–∏–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ LM</b>", "–ö–∞–∂–¥–∞—è –º–µ—Ç—Ä–∏–∫–∞ ‚Äî –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ –±–µ–∑ –ò–ò."]
    for section in METHODOLOGY_SECTIONS:
        lines.append(f"\n<b>{section['title']}</b>")
        for detail in section["lines"]:
            lines.append(f"‚Ä¢ {detail}")
    lines.append("\n–°–ª–æ–≤–∞—Ä–∏ –∏ —Ñ–∞–∫—Ç—ã —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è: —Ç–∞–±–ª–∏—Ü—ã <code>lm_dictionary_terms</code> –∏ <code>lm_dictionary_hits</code>.")
    keyboard: List[List[InlineKeyboardButton]] = []
    if back_callback:
        keyboard.append([InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data=back_callback)])
    return Screen(text="\n".join(lines), keyboard=keyboard)


def _format_with_word(count: int, forms: Tuple[str, str, str]) -> str:
    return f"{count} {forms[_word_form_index(count)]}"


def _word_form_index(count: int) -> int:
    count = abs(count)
    if 11 <= count % 100 <= 14:
        return 2
    last = count % 10
    if last == 1:
        return 0
    if 2 <= last <= 4:
        return 1
    return 2


_HTML_TAG_RE = re.compile(r"</?[^>]+>")


def _strip_html(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç HTML-—Ç–µ–≥–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    return _HTML_TAG_RE.sub("", text)


def _format_period_label(start: Optional[date], end: Optional[date]) -> str:
    if not start or not end:
        return "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö"
    if start == end:
        return start.strftime("%d %b %Y")
    same_month = start.month == end.month and start.year == end.year
    if same_month:
        return f"{start.strftime('%d')}‚Äì{end.strftime('%d %b %Y')}"
    return f"{start.strftime('%d %b')}‚Äì{end.strftime('%d %b %Y')}"


def _format_datetime(value: Optional[Any]) -> str:
    if not value:
        return "–Ω/–¥"
    try:
        if isinstance(value, datetime):
            dt = value
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            dt = dt.astimezone(MOSCOW_TZ)
            return f"{dt.strftime('%d %b %Y %H:%M:%S')} MSK"
        return str(value)
    except Exception:
        return str(value)


def _format_share(count: int, total: int) -> str:
    if not total:
        return ""
    percent = (count / total) * 100
    return f" ({percent:.0f}%)"


def _format_score(value: Optional[Any], *, precision: int = 1) -> str:
    if value is None:
        return "‚Äî"
    try:
        number = float(value)
    except (TypeError, ValueError):
        return "‚Äî"
    fmt = f"{{:.{precision}f}}"
    text = fmt.format(number)
    if precision == 0:
        return text.split(".")[0]
    return text.rstrip("0").rstrip(".")


def _format_percent(value: Optional[Any]) -> str:
    if value is None:
        return "‚Äî"
    try:
        number = float(value) * 100
    except (TypeError, ValueError):
        return "‚Äî"
    return f"{number:.0f}%"


def _format_delta_suffix(value: Optional[Any], *, precision: int = 1) -> str:
    if value is None:
        return ""
    try:
        number = float(value)
    except (TypeError, ValueError):
        return ""
    if abs(number) < 10 ** (-precision):
        return ""
    fmt = f"{{:+.{precision}f}}"
    text = fmt.format(number)
    if precision == 0:
        text = text.split(".")[0]
    return f" ({text} –∫ –ø—Ä–æ—à–ª–æ–º—É –ø–µ—Ä–∏–æ–¥—É)"


def _status_from_value(value: Optional[Any], green_from: float, yellow_from: float) -> str:
    if value is None:
        return "gray"
    try:
        numeric = float(value)
    except (TypeError, ValueError):
        return "gray"
    if numeric >= green_from:
        return "green"
    if numeric >= yellow_from:
        return "yellow"
    return "red"


def _status_from_share(value: Optional[Any], green_limit: float, yellow_limit: float) -> str:
    if value is None:
        return "gray"
    if value <= green_limit:
        return "green"
    if value <= yellow_limit:
        return "yellow"
    return "red"


def _safe_ratio(count: Optional[int], total: int) -> Optional[float]:
    if not total:
        return None
    try:
        return float(count or 0) / total
    except ZeroDivisionError:
        return None


def _describe_action_item(action_type: str, item: Dict[str, Any]) -> Tuple[str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–ø—Ä–∏—á–∏–Ω—ã, –¥–µ–π—Å—Ç–≤–∏–µ) –¥–ª—è —ç–ª–µ–º–µ–Ω—Ç–∞ —Å–ø–∏—Å–∫–∞ –¥–µ–π—Å—Ç–≤–∏–π.
    """
    from app.services.lm_rules import EVIDENCE_RULES, METRIC_CONFIG
    
    rules = EVIDENCE_RULES.get(action_type, [])
    found_reasons: List[str] = []

    meta_payload = item.get('value_json')
    meta_dict: Optional[Dict[str, Any]] = None
    if isinstance(meta_payload, str):
        try:
            meta_payload = json.loads(meta_payload)
        except (json.JSONDecodeError, TypeError, ValueError) as exc:
            logger.warning("LM screens: –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å meta_payload: %s", exc)
            meta_payload = None
        except Exception:
            logger.exception("LM screens: –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ meta_payload")
            raise
    if isinstance(meta_payload, dict):
        meta_dict = meta_payload
        meta_reasons = meta_payload.get('reasons') or []
        if meta_reasons:
            found_reasons.extend(meta_reasons[:2])
        elif meta_payload.get('reason'):
            found_reasons.append(meta_payload['reason'])
        hits = meta_payload.get('hits') or []
        for hit in hits[:1]:
            term = hit.get("term")
            snippet = hit.get("snippet")
            if term:
                line = f"–¢—Ä–∏–≥–≥–µ—Ä ¬´{term}¬ª"
                if snippet:
                    line += f": {snippet}"
                found_reasons.append(line)
        snippets = meta_payload.get("snippets") or []
        if snippets:
            found_reasons.append(f"‚§∑ {snippets[0]}")
        if meta_payload.get("loss_category"):
            found_reasons.append(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {meta_payload['loss_category']}")
        if meta_payload.get("requires_reason"):
            found_reasons.append("‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–∏—á–∏–Ω—É –æ—Ç–∫–∞–∑–∞.")
    
    for r in rules:
        if len(found_reasons) >= 2:
            break
        try:
            condition = r.get('condition')
            reason_template = r.get('text')
            if condition and condition(item):
                reason_text = reason_template.format(**item) if reason_template else ""
                found_reasons.append(reason_text)
        except (KeyError, TypeError, ValueError) as exc:
            logger.warning("LM screens: –æ—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—Ä–∏—á–∏–Ω—ã (%s)", exc)
            continue
        except Exception:
            logger.exception("LM screens: –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∞–≤–∏–ª–∞")
            raise
                
    if action_type == "followup":
        source_bits: List[str] = []
        reason_codes = set((meta_dict or {}).get("reason_codes") or [])
        if "OPERATOR_WILL_CLARIFY" in reason_codes:
            source_bits.append("–æ–ø–µ—Ä–∞—Ç–æ—Ä –æ–±–µ—â–∞–ª —É—Ç–æ—á–Ω–∏—Ç—å")
        refusal_group = item.get("refusal_group")
        if refusal_group:
            source_bits.append(f"–≥—Ä—É–ø–ø–∞ –æ—Ç–∫–∞–∑–∞: {refusal_group}")
        result_text = str(item.get("result") or "").strip()
        if result_text:
            snippet = result_text[:120]
            if len(result_text) > 120:
                snippet = snippet.rstrip() + "‚Ä¶"
            source_bits.append(f"result: {snippet}")
        if source_bits:
            found_reasons.append("–ò—Å—Ç–æ—á–Ω–∏–∫: " + " | ".join(source_bits))

    reasons = "; ".join(found_reasons) if found_reasons else "–¥—Ä—É–≥–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏"
    
    mapping = {
        "followup": "followup_needed_flag",
        "complaints": "complaint_risk_flag",
        "lost": "lost_opportunity_score",
        "churn": "churn_risk_level"
    }
    
    conf_key = mapping.get(action_type)
    action_text = METRIC_CONFIG.get(conf_key, {}).get("action_text", "–†–∞–∑–æ–±—Ä–∞—Ç—å –∫–µ–π—Å.")
    if action_type == "followup":
        sla_hours = None
        if meta_dict:
            sla_hours = meta_dict.get("sla_hours")
        sla_value = int(sla_hours) if isinstance(sla_hours, (int, float)) else 24
        action_text = f"{action_text} (SLA ‚â§ {sla_value} —á.)"
    
    return reasons, action_text


def _shorten_text(value: Optional[str], limit: int = 220) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã –¥–ª—è —Å–ø–∏—Å–∫–æ–≤ LM."""
    if not value:
        return "‚Äî"
    text = str(value).strip()
    if len(text) <= limit:
        return text
    trimmed = text[: limit - 1].rstrip()
    return trimmed + "‚Ä¶"


def _extract_operator_name(raw: Optional[str]) -> Optional[str]:
    if not raw:
        return None
    name = raw.strip()
    if not name:
        return None
    digits = re.sub(r"\D+", "", name)
    if digits and len(digits) >= 7:
        return None
    return name
